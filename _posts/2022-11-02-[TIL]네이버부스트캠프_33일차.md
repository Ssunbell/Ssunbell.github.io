---
title:  "[TIL/네이버 부스트캠프]TIL 32일차 대회 7일차"
date: '2022-11-01 16:59:00 +09:00'
category: [네이버 부스트캠프 AI Tech 4기, TIL]
tags: [네이버, 부스트캠프, 네이버부스트캠프, AI Tech, 부스트캠프 AI Tech 4기]
use_math: true
---
## 배운 것들
1. 자연어 처리 경진대회 팁
   1. 결측치 분석
      - Nan 값은 가장 많이 등장하는 데이터나 의미 없는 데이터로 치환
      - 숫자일 경우 보간법 사용
   3. 라벨
      - Train, Dev, Test데이터 개수 및 비율 확인
      - Train Label과 Dev Label의 분포
   4. 토크나이징 결과 분석
      - 문장길이 기술분석
   5. 성능 검증 : 일반화를 위한 성능 검증
      - Validation 데이터셋 활용 or train set과 dev set을 합쳐서 활용
      - 언더피팅과 오버피팅을 방지하기 위해
        - 언더피팅 해결책 : 데이터 늘리기, 모델을 복잡하게 만들기, 학습량 늘리기
        - 오버피팅 해결책 : 데이터 늘리기, 모델을 간단하게 만들기, Dropout, Early Stop 사용하기
   6. 세부 측정 방법 
        - Macro : 평균의 평균
        - Micro : 모든 클래스를 총합하여 평균낸 것
        - Weight : 각 클래스의 평균에 가중치를 곱해서 합한 것
   7. 앙상블
      1. k-fold Cross Validation : 학습 데이터를 최대한 활용하기 위해 K등분하여 K번 학습(성능 향상에 좋음)
      2. Voting : Soft Voting이 성능이 더 좋음(확률을 평균냄)
      3. Bagging : Bootstrap 샘플링 방식으로 데이터를 구성하여 여러 번 학습하는 것. 일반화 성능이 좋음
      4. Boosting : Bagging과 비슷하지만 모델을 순차적으로 학습하여 에러를 개선해나감, 어려운 문제를 잘 맞춤
      5. Stacking : 여러 모델의 예측 결과를 종합하여 새로운 모델의 입력 데이터로 활용
      6. Shake-up : Pulic과 Private 순위가 뒤바뀌는 현상
         1. Public과 Private 순위가 뒤바뀌는 현상
         2. 학습 및 평가 데이터가 너무 적을때
         3. 모델의 일반화 능력이 부족할 때
         4. 학습 데이터에 오버피팅되었을 때
   8. Test 데이터가 없는 경우 무조건 Test 데이터를 만들고 혹은 Train에서 떼어냄
   9. early stopping은 validation loss로 기준을 잡음

## 느낀 것들
대회에 필요한 다양한 스킬들을 익혀야 될 것 같음
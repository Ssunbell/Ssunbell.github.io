---
title:  "[TIL/네이버 부스트캠프]TIL 44일차 GPT"
date: '2022-11-17 16:59:00 +09:00'
category: [네이버 부스트캠프 AI Tech 4기, TIL]
tags: [네이버, 부스트캠프, 네이버부스트캠프, AI Tech, 부스트캠프 AI Tech 4기]
use_math: true
---
## 배운 것들
GPT의 한계점
- fine-tuning된 모델은 다른 Task에서 사용 불가능
- "언어"의 특성상 지도학습의 목적 함수는 비지도 학습의 목적함수와 같다. 즉 fine-tuning은 필요없다고 정의
- 엄청 큰 데이터셋을 사용하면 자연어 task(감정, 분류 등)를 자연스럽게 학습
- 즉, zero-shot, one-shot, few-shot을 통해 fine-tuning과 비슷한 효과를 냄
  - 인간이 새로운 학습을 위해 수많은 데이터를 필요로 하지 않음
  - fine-tuning으로 한가지 Task만 수행할 수 있도록 하는 것은 바보같은 짓

한계점
- Large Corpus 내의 대답에서만 생성 가능 -> 새로운 데이터 업데이트 필요
- 모델 사이즈만 키우면 다 해결될것인가?
- 멀티 모달의 정보가 필요
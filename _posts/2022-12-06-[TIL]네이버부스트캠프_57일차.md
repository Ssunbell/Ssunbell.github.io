---
title:  "[TIL/네이버 부스트캠프]TIL 51일차 데이터 제작 가이드라인"
date: '2022-12-06 16:59:00 +09:00'
category: [네이버 부스트캠프 AI Tech 4기, TIL]
tags: [네이버, 부스트캠프, 네이버부스트캠프, AI Tech, 부스트캠프 AI Tech 4기]
use_math: true
---
## 배운 것들

### 원시 데이터
- 과제를 해결하기 위해 특정 도메인, 장르, 주제 등에 대하여 조건에 맞춰 수집하였으나, 주석 단계를 거치지 않은 상태의 데이터
- 원하는 형태로 가공하기 이전의 데이터로 목적에 맞는 전처리 과정을 거쳐 가공이 되어야 함

- 원시 텍스트 수집 시 검토 사항
    - What : 수집 대상, 포함 요소
    - When : 수집 기간
    - Where : 수집 장소
    - Who : 담당자
    - How : 수집 방법, 수집 주기, 데이터 형식, 규모
    - Why : 수집 목적, 기대 결과

> 데이터 메타 정보 예시

- 데이터셋 식별자, 이름, 폴더 위치, 레이블 폴더 위치, 데이터셋 카테고리, 데이터셋 타입

- 원시 데이터 수집 시 고려사항
    - 획득 가능성 : 가공이 많이 필요한 비용이 많은 데이터는 어려움, 트래픽량, 저장 처리 장치의 용량
    - 데이터 균형과 다양성 : 개체의 다양성, 목적 및 상황의 다양성, 시간별, 종류별, 사람별, 지역별 다양성
    - 신뢰성 : 데이터의 품질이 신뢰할 수 있는지 검토
    - 법 제도 준수 : 개인정보 및 사생활 보호

> 저작권

|원시 데이터(1차적 저작물)|주석작업|데이터셋(2차적 저작물)|
|:---:|:---:|:---:|
|라이센스 : CC BY-SA|작업 가능|라이센스 : CC-BY-SA 가능|
|라이센스 : CC BY-SA|작업 불가능|x|
|라이센스 : CC BY-NC-SA|작업 가능|라이센스 : CC BY-SA 불가능|

> 주석 도구의 종류

- Brat
- Doccano
- tagtog

### 데이터 구축 프로세스
1. 과제 정의
2. 데이터 수집
3. 데이터 정제
4. 데이터 주석
5. 데이터 검수
6. 데이터 학습

> The MATTER cycle

Model -> Annotate -> train -> test -> evaluate -> revise

> MAMA cycle

Model and Guidelines -> Annotate -> Evaluate -> Revise

> 예시

- 파일럿 구축 -> 파일럿 검수 -> 1차 구축 -> 1차 검수 -> 2차 구축 -> 최종 검수

#### 데이터 주석
1. 분류 : 감성 분석, 주제 분류, 자연어 추론 등
2. 특정 범위(span) 주석 : NER
3. 대상 간 관계 주석 : 개체명 연결, 관계 추출, 구문 분석(특정 범위 주석이 선결조건)
4. 텍스트 생성 : 대화문, 번역, 요약 등
5. 복합 유형 : 질의 응답, 슬롯필링 대회(앞선 유형의 데이터 구축 방식을 복합적으로 사용)

#### 데이터 검수

- 가이드라인 정합성 : 각 주석 절차 및 주석 내용이 가이드 라인에 부합하는지 확인
- 데이터 형식 : 메타 정보, 레이블, 텍스트 내용 등의 형식이 맞는지 확인
- 통계 정보 : 메타 정보 및 레이블의 분포, 문장 길이, 단위 별 규모 확인
- 모델 성능 확인 : 모델 학습을 통해 결과값 확인

#### 데이터 구축 프로세스 설계 시 유의 사항
오류 원인 분석
- 구축 방법 측면의 오류 원인 : 대상 선정, 수집, 정제 라벨링 등의 통제 미흡
- 가이드라인 측면의 오류 원인 : 구축 가이드라인의 불완전성, 작업자간 서로 상이하게 작업을 수행하거나 데이터간 일관성 위배
- 데이터셋 측면의 오류 원인 : 데이터셋 설계의 부족, 구문정확성 위배, 데이터 구축 중복 등
- 학습모델 측면의 오류 원인

> 표본 추출 vs 전수 검사

> 작업자 간 일치도를 위해 동시에 작업하면 좋지만 어떤 기준을 가지고 평가 : Cohen's k, Fleiss's k 를 이용

> 모델 평가 : 정확도, 정밀도, 재현율, F1


### 데이터 구축 가이드라인 기초
#### 1. 가이드라인의 유형
- 목적 : 수집을 위한 가이드라인, 주석을 위한 가이드라인, 검수를 위한 가이드라인
- 제시 방식 : 문서형, 화면 노출형/튜토리얼형

#### 2. 가이드라인의 구성 요소
- 데이터를 왜 구축해야 하는지를 설명할 때가 설명하지 않을 때보다 좋은 경우가 많음
- 데이터 수집 및 정제 작업 : 데이터 정의, 수집 데이터 특성 분석, 수집 데이터 정제 방식, 수집 도구 및 정제 도구, 수집 시 고려 사항
- 데이터 주석 작업 : 데이터 특성 분류 체계, 데이터 주석 방법 및 절차, 데이터 주석 형식과 정의, 데이터 주석 도구 사용법, 데이터 주석 완료 후 관리 방법, 반려 및 통과 기준
- 데이터 검수 및 평가 : 검수 절차 정의, 검수 방식, 평가 지표, 검수 결과 분석법, 검수 결과 반영법



#### 3. 가이드라인의 버전 관리
#### 4. 가이드라인 작성 도구
- 노션
- 구글 독스
#### 5. 가이드라인 작성 시 유의사항
- 가이드라인의 유형별 특성을 이해하고 그에 알맞는 정보를 작성한다.
- 작업자의 작업 이해도를 고려하여 작성한다.
- 작업자에게 공개해야 하는 필수 정보와 부가적인 정보가 무엇인지 사전에 고려한다.
- 가이드라인 구성 요소의 배치를 어떻게 할 지 고민한다.
- 작업자의 가독성을 고려한다.


### 관계 추출의 개요
- 문장을 분석 대상으로 삼아서 문장에 출현한 개체명의 경계를 인식하고, 각 개체명에 해당하는 태그를 주석
- KLUE에서는 국제적인 기준에서 가장 널리 알려진 CoNLL 2003의 태그 체계 및 Stanford NER을 바탕으로 국내 TTA 표준 지침의 주석 가이드라인에 따라 데이터를 구축함. PS(사람), LC(지역), OG(기관), DT(날짜), TI(시간), QT(수량)
- MUC-7(ORG, PER, LOC) -> CoNLL2003(MISC 추가)

> 관계 추출

- 관계 추출은 문장에서 나타난 개체명 쌍(Entity Pair)의 관계(Relation)을 판별하는 Task

> 개체명 연결

- 개체명을 인식하고 모호성을 해소(Named ENtity Disambiguation)하는 과제를 결합한 것. 텍스트에서 추출된 개체명을 지식 베이스(Knowledge base)와 연결하여 모호성을 해소함. 가령 Kashmir가 노래 제목이랑 지역과 겹칠 수 있는데 해당 데이터를 해당 항목과 연결

- AIDA CoNLL-YAGO Dataset 또는 TAC KBP English Entity Linking Comprehensive and Evaluation Data 2010 등이 있음.

### 데이터 제작시 문제점

- 2개 이상의 태그로 주석될 수 있는 개체명 : 맥락의 기반해서 주석(but, 작업자마다 다름)
- 주석 대상의 범주
- 한국어 데이터 현실에 맞지 않는 주석 -> 태그 통폐합 및 추가
- KB의 활용 -> 일부만 활용
- 적합한 KB 선정의 문제 : 현재 AI HUB에 공개된 KB의 경우 제한적인 저작권 아래서 활용이 가능함. 위키 데이터를 활용하여 자체적인 지식베이스를 구축하여 활용하거나, 서비스 도메인에 맞는 지식 베이스를 구축하여 활용할 수 있음. 지식 베이스를 구축하는 것 자체가 많은 비용과 자원이 드는 일이므로 이에 대한 대비가 필요함.

### Knowlegde Graph
- Basics : Elementary unit of a knowledge graph is a triplet subject-predicate-object, often denoted as (head, relation, tail) or (h, r, t)

> 관계 추출 등은 챗봇, 검색 엔진 등에서 사용 가능
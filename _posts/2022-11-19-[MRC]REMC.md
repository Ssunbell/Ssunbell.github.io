---
title:  "[MRC]Enhancing Targeted Minority Class Prediction in Sentence-Level Relation Extraction 논문 리뷰"
date: '2022-11-19 13:59:00 +09:00'
category: [논문, Moosic하게 Reading Comprehension]
tags: [NLP, 대회, RE, NER]
use_math: true
---

![](/assets/img/B/b0.png)

# 무식하게 논문읽기(MRC) REMC 편🔥

## 초록
문장 단위의 관계 추출(RE)은 약 80퍼센트의 데이터의 라벨이 "no relation"인 부정(Negative) 라벨로 데이터 분포가 **불균형**하다는 것과 긍정(positive) 라벨 사이에 마이너한 클래스(여기서는 MC; Minority Classes)들이 존재하고 심지어는 그 MC가 잘못 라벨링되어있는 경우도 존재한다는 문제점이 있다. 라벨 노이즈와 낮은 source라는 도전과제들 때문에 대부분의 모델은 MC를 학습하는데 실패하게 되고 거의 0에 수렴하거나 매우 낮은 F1 스코어를 얻게 된다. 그러나 이전의 연구들에서는 micro F1에만 집중하고 MC에 대해서는 적절하게 대처하지 않았다. 이러한 MC에 대해 잘못 분류되는 문제를 해결하기 위해 우리는 (1) **MC에 집중(attention)하는 모듈(MCAM)**과 효과적으로 RE에 특화되어 **증강**하는 방법론을 소개한다. MCAM은 증강 기법을 위해 신뢰할만한 하나의 MC를 선택하기 위해 MC의 신뢰도 점수(confidence scores)를 계산한 후 훈련 과정에서 MC의 정보를 집계(aggregate)한다. 우리의 실험은 MC의 F1 score를 놀랍도록 높게 상승시킬수 있었을 뿐만 아니라 TACRED에서 SOTA를 달성할 수 있었다.

> Abstract: Sentence-level relation extraction (RE) has a highly imbalanced data distribution that about 80% of data are labeled as negative, i.e., no relation; and there exist minority classes (MC) among positive labels; furthermore, some of MC instances have an incorrect label. Due to those challenges, i.e., label noise and low source availability, most of the models fail to learn MC and get zero or very low F1 scores on MCs. Previous studies, however, have rather focused on micro F1 scores and MCs have not been addressed adequately. To tackle high mis-classification errors for MCs, we introduce (1) a minority class attention module (MCAM), and (2) effective augmentation methods specialized in RE. MCAM calculates the confidence scores on MC instances to select reliable ones for augmentation, and aggregates MCs information in the process of training a model. Our experiments show that our methods achieve a state-of-the-art F1 scores on TACRED as well as enhancing minority class F1 score dramatically.
---
title:  "[TIL/네이버 부스트캠프]TIL 36일차 MLOps 개론"
date: '2022-11-07 16:59:00 +09:00'
category: [네이버 부스트캠프 AI Tech 4기, TIL]
tags: [네이버, 부스트캠프, 네이버부스트캠프, AI Tech, 부스트캠프 AI Tech 4기]
use_math: true
---
## 배운 것들
실제 Service 단계에서 겪는 어려움
1. 모델의 결과값이 이상한 경우가 존재 -> 원인 파악, Outlier가 존재할경우 제외가 필요
2. 모델의 성능이 계속 변경 -> 모델의 성능을 어떻게 계속 확인할 수 있을까?(예측값과 실제값의 차이)
3. 새로운 모델이 더 안 좋다면? -> 과거의 모델을 그대로 사용할 것인지, Research의 모델이 실제 Product에 잘 적용될지

MLOps란?
1. 머신러닝 엔지니어링 + 데이터 엔지니어링 + 클라우드 + 인프라
2. 모신러닝 모델 개발(ML Dev)과 머신러닝 모델 운영(Ops)에서 사용되는 문제, 반복을 최소화하고 비즈니스 가치를 창출하는 것이 목표
3. 모델링에 집중할 수 있도록 관련 인프라를 만들고 자동화를 만듬
4. MLOps의 목표는 빠른 시간 내에 가장 적은 위험을 부담하며 아이디어 단계부터 Production 단계까지 ML 프로젝트를 진행할 수 있도록 기술적 마찰을 줄이는 것

Model Serving
1. 머신러닝 모델을 개발하고, 앱 or 웹에서 사용할 수 있게 만드는 행위
2. 서비스화라고 표현할 수 있음
3. 크게 두가지 방식이 존재
   1. Online Serivng
   2. Batch Serving
   3. Edge Serving(클라우드)
4. Serving : 모델을 웹/앱 서비스에 배포하는 과정, 모델을 활용하는 방식, 모델을 서비스화하는 관점
5. inference : 모델에 데이터가 제공되어 예측하는 경우, 사용하는 관점

6. 웹 서버 
   - HTTP를 통해 웹 브라우저에서 요청하는 HTML 문서나 오브젝트를 전송해주는 서비스 프로그램
   - 요청(Request)을 받으면 요청한 내용을 보내주는(Response) 프로그램

문제 정의의 중요성
- 특정 현상을 파악하고 그 현상에 있는 문제를 정의하는 과정, 문제를 잘 풀기 위해서는 정의가 매우 중요
1. 현상 파악 - 어떤 일이 발생?, 어려움? 해결하면 좋은 것? 어떤 가설? 어떤 데이터?
2. 구체적인 문제 정의 - 무엇을 해결하고 싶은가? 무엇을 알고 싶은가? 더 구체적인 명확한 용어로 정리하기, 시간의 제약 파악
3. 프로젝트 설계 - 문제 정의 -> 최적화할 Metric -> 데이터 수집, 레이블 확인 -> 모델 개발 -> 모델 예측 결과를 토대로 Error Analysis / 머신러닝 문제 타당성 확인
   - 학습할 수 있는 패턴이 있는가?
   - 목적함수를 어떻게 정의할 것인가?
   - 패턴이 복잡해야 함
   - 비윤리적, 한번의 예측 오류가 치명적일 경우, 비용 효율적이지 않을 경우 지양
   - Goal/Objectives를 통해 큰 목적/세부 목표를 나눔
   - 목적함수가 여러개일 경우 분리하는 것이 좋음
제약조건
   - Baseline : 새로 만든 모델을 무엇과 비교할 것인가?
   - Threshold : 확률값이 0.5 이상일 경우 강아지라고 할것인지 아니면 0.7로 할것인지
   - Performace Trade-off : 속도가 빠른데 정확도가 더 낮은걸 쓸지 아니면 속도가 느린데 정확도가 높은 것을 쓸지
   - 해석 가능 여부
   - Confidence Measurement : False negative가 있어도 괜찮은지, 오탐이 있으면 안되는지
Metric Evaluation
   - 앞선 문제를 해결할 경우 어떤 지표가 좋아질까? (매출, 재방문율 등 비즈니스 지표를 포함)

비즈니스 모델
   - 
## 느낀 것들
대회 성적보다는 라벨에 대한 정량/정성적 평가가 중요해보임
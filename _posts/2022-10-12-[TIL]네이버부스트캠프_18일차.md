---
title:  "[TIL/네이버 부스트캠프]TIL 18일차 word2vec"
date: '2022-10-12 16:59:00 +09:00'
category: [네이버 부스트캠프 AI Tech 4기, TIL]
tags: [네이버, 부스트캠프, 네이버부스트캠프, AI Tech, 부스트캠프 AI Tech 4기]
use_math: true
---
## 배운 것들

1. Naive Bayes classifier는 최대우도 추정법을 이용해서 분류
2. 단어를 원핫 벡터로 표현하면 코사인 유사도가 0이므로 단어간 관계를 파악하기 어려움
3. 워드 임베딩은 단어를 워드 임베딩 알고리즘을 통해 임베딩 벡터를 뽑아내는 과정을 의미
4. 이는 밀집 벡터로 표현하며, 좌표 공간의 차원 수를 결정하여 임베딩 벡터를 얻을 수 있음
5. 워드 임베딩은 비슷한 의미를 가진 단어가 비슷한 위치에 맵핑하는 것이 기본 아이디어

> GloVe
1. 워드 임베딩은 윈도우 안에 여러번 나타나는 단어를 중복하여 학습하기 때문에 학습 속도가 느리고 빈도수에 의해 결정됨
2. 하지만, GloVe는 사전에 구한 Co-occurence matrix를 이용해서 확률을 구함

## 느낀점
1. 워드 임베딩에 대해 모호했는데 그 방법론을 어느정도 학습한 것 같다.
